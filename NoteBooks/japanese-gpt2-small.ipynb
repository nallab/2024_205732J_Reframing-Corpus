{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyM50jLPNd9PlrTULobuPXZO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"69d370fe94c148b5b4bfba841de38a42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5abc24b5c65442d1be2e5087d60f4a29","IPY_MODEL_688046bebd264d8da70a938d00773258","IPY_MODEL_fb7c5e3c76204bcdb84112316d1a5322"],"layout":"IPY_MODEL_388fa978c6bd453a832062d385b4a603"}},"5abc24b5c65442d1be2e5087d60f4a29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_497e4336d1004c4ca7ebf3a0e7837518","placeholder":"​","style":"IPY_MODEL_0f310f9922b447708bab5ccbf14c751f","value":"tokenizer_config.json: 100%"}},"688046bebd264d8da70a938d00773258":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_758d40f565c649cd858d7e22d7124c9c","max":282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_24e27ceb08f64393985215ba6e59171e","value":282}},"fb7c5e3c76204bcdb84112316d1a5322":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3402fc06712244c6af566b454f7765cb","placeholder":"​","style":"IPY_MODEL_e592d13cae9b43ec9a342816b6f11621","value":" 282/282 [00:00&lt;00:00, 23.1kB/s]"}},"388fa978c6bd453a832062d385b4a603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"497e4336d1004c4ca7ebf3a0e7837518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f310f9922b447708bab5ccbf14c751f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"758d40f565c649cd858d7e22d7124c9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24e27ceb08f64393985215ba6e59171e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3402fc06712244c6af566b454f7765cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e592d13cae9b43ec9a342816b6f11621":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0690ad87b5914cc3ae4793d30d7d5e0f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3bec4bae60a7457eaf8686882761eccf","IPY_MODEL_eb14099137f4498aae252c528dfe0635","IPY_MODEL_98cfde9814544668a568372826e81994"],"layout":"IPY_MODEL_51a7f78cd79e41f8abfd545edd1b411d"}},"3bec4bae60a7457eaf8686882761eccf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f392ae8c3874c1aa9bf161e124e8ca1","placeholder":"​","style":"IPY_MODEL_cf1fa6ea88554220991928cdf35d384b","value":"spiece.model: 100%"}},"eb14099137f4498aae252c528dfe0635":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c17239edab094cfe87e18fc5b7889929","max":805634,"min":0,"orientation":"horizontal","style":"IPY_MODEL_101a19bc18454597b3babd9708cc33dd","value":805634}},"98cfde9814544668a568372826e81994":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e90b4cd158384f3e9e64c4b581f8a441","placeholder":"​","style":"IPY_MODEL_83de77b3c88c404fac8618836e9b929d","value":" 806k/806k [00:00&lt;00:00, 16.4MB/s]"}},"51a7f78cd79e41f8abfd545edd1b411d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f392ae8c3874c1aa9bf161e124e8ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf1fa6ea88554220991928cdf35d384b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c17239edab094cfe87e18fc5b7889929":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"101a19bc18454597b3babd9708cc33dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e90b4cd158384f3e9e64c4b581f8a441":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83de77b3c88c404fac8618836e9b929d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0cc59721d6c44ef6b4f865aa358b76af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f9ae365d047f45b8b4878d9057766448","IPY_MODEL_b053e35c9e1c45e39b3aec2cd94dde42","IPY_MODEL_ad5bbc34a4f34ff89d3832eb8fb75775"],"layout":"IPY_MODEL_506de4cccf914574a6e16b816c2287fa"}},"f9ae365d047f45b8b4878d9057766448":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_192982fb3a934d0595c44c2d8abbcd5b","placeholder":"​","style":"IPY_MODEL_d893334e4cfe467da570316256336cdc","value":"special_tokens_map.json: 100%"}},"b053e35c9e1c45e39b3aec2cd94dde42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96d37264fbab4436b3a86041338bd386","max":153,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2dd1a8e2c4b24dab81fdb0bb28ae86c1","value":153}},"ad5bbc34a4f34ff89d3832eb8fb75775":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77d0094576b4428c927d9755f6c4bbab","placeholder":"​","style":"IPY_MODEL_fcc53c9c420846e68bb117a9337a62ed","value":" 153/153 [00:00&lt;00:00, 10.2kB/s]"}},"506de4cccf914574a6e16b816c2287fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"192982fb3a934d0595c44c2d8abbcd5b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d893334e4cfe467da570316256336cdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96d37264fbab4436b3a86041338bd386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dd1a8e2c4b24dab81fdb0bb28ae86c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"77d0094576b4428c927d9755f6c4bbab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fcc53c9c420846e68bb117a9337a62ed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efb324f821da4bdd8de768f1fe0eddca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f55c4dd56e7f457a9e0bdfcf5eda8883","IPY_MODEL_4c78b375a65b4ee5b56dad6d40e2c087","IPY_MODEL_e535633230874775ae0fdfa5fc56faa7"],"layout":"IPY_MODEL_e20978016e974e4a8bf76dfb9fe3794b"}},"f55c4dd56e7f457a9e0bdfcf5eda8883":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_85d554f3098348849832b19f85dbd804","placeholder":"​","style":"IPY_MODEL_1bc91d25aa4047ed8f1028966529bc39","value":"config.json: 100%"}},"4c78b375a65b4ee5b56dad6d40e2c087":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50f9ce2b998148b99787602d6e9b0291","max":846,"min":0,"orientation":"horizontal","style":"IPY_MODEL_df7a0796d1fc44a8b73729cece4d65e7","value":846}},"e535633230874775ae0fdfa5fc56faa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e9bcbcfbf6448f0a38d2c6f6475d425","placeholder":"​","style":"IPY_MODEL_f82a308456ec40df93a1352840efdebf","value":" 846/846 [00:00&lt;00:00, 68.3kB/s]"}},"e20978016e974e4a8bf76dfb9fe3794b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85d554f3098348849832b19f85dbd804":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1bc91d25aa4047ed8f1028966529bc39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50f9ce2b998148b99787602d6e9b0291":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df7a0796d1fc44a8b73729cece4d65e7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e9bcbcfbf6448f0a38d2c6f6475d425":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82a308456ec40df93a1352840efdebf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9397caf95f4b40569cd07e1aae27d210":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bbd29fac9d4f489dba1488042e1f1864","IPY_MODEL_c984413f875b4a7b896f1d9971f3f40c","IPY_MODEL_19bc695a0eae4e01b6c5d73ab5dbbd88"],"layout":"IPY_MODEL_17651c5754f2464d9f0aa3cf4f9b2c59"}},"bbd29fac9d4f489dba1488042e1f1864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8084712258534cd8bc59bb5f47377a03","placeholder":"​","style":"IPY_MODEL_0d64a132b45844edac1059c4a867bad8","value":"model.safetensors: 100%"}},"c984413f875b4a7b896f1d9971f3f40c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fde8e611da7249ed8127db2a26f23ad3","max":454274094,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e336e3d8618a439296419cbb5957e8c8","value":454274094}},"19bc695a0eae4e01b6c5d73ab5dbbd88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_259f18283e9843bc86871b3cf02a1e2a","placeholder":"​","style":"IPY_MODEL_0b21912d11f84f05970351739b13c737","value":" 454M/454M [00:02&lt;00:00, 227MB/s]"}},"17651c5754f2464d9f0aa3cf4f9b2c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8084712258534cd8bc59bb5f47377a03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d64a132b45844edac1059c4a867bad8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fde8e611da7249ed8127db2a26f23ad3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e336e3d8618a439296419cbb5957e8c8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"259f18283e9843bc86871b3cf02a1e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b21912d11f84f05970351739b13c737":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 準備"],"metadata":{"id":"96sAjJ5mG95b"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IAMjlak3G2Ve","executionInfo":{"status":"ok","timestamp":1705556933056,"user_tz":-540,"elapsed":22155,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"cb0b0c88-3878-457e-cc4d-4179a861503d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}],"source":["# googleドライブのマウント\n","from google.colab import drive\n","drive.mount('drive')"]},{"cell_type":"code","source":["# 依存ライブラリのインストール\n","!git clone https://github.com/huggingface/transformers.git\n","!cd transformers\n","!pip install -qU ./transformers sentencepiece transformers[torch] datasets evaluate mecab-python3 unidic-lite"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x7qZcNZIHBsR","executionInfo":{"status":"ok","timestamp":1705557166626,"user_tz":-540,"elapsed":56186,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"33881919-a79b-4e25-fa1c-7643ba2fe393"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 178140, done.\u001b[K\n","remote: Counting objects: 100% (46507/46507), done.\u001b[K\n","remote: Compressing objects: 100% (2029/2029), done.\u001b[K\n","remote: Total 178140 (delta 45298), reused 44485 (delta 44477), pack-reused 131633\u001b[K\n","Receiving objects: 100% (178140/178140), 175.86 MiB | 30.29 MiB/s, done.\n","Resolving deltas: 100% (129642/129642), done.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m581.7/581.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# data: 学習用データセット格納用\n","# model: 学習済みモデル格納用\n","!mkdir -p data model"],"metadata":{"id":"3C85Ayn2ICp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 事前学習済みモデル\n","PRETRAINED_MODEL_NAME = \"rinna/japanese-gpt2-small\"\n","\n","# 転移学習済みモデル\n","MODEL_DIR = \"model/final_output\""],"metadata":{"id":"QEhr9QEBIW26"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import T5Tokenizer, AutoModelForCausalLM\n","\n","# gpt2の事前学習済みトークナイズをロード\n","tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL_NAME, is_fast=True)\n","# gpt2の事前学習済みモデルをロード\n","model = AutoModelForCausalLM.from_pretrained(PRETRAINED_MODEL_NAME)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322,"referenced_widgets":["69d370fe94c148b5b4bfba841de38a42","5abc24b5c65442d1be2e5087d60f4a29","688046bebd264d8da70a938d00773258","fb7c5e3c76204bcdb84112316d1a5322","388fa978c6bd453a832062d385b4a603","497e4336d1004c4ca7ebf3a0e7837518","0f310f9922b447708bab5ccbf14c751f","758d40f565c649cd858d7e22d7124c9c","24e27ceb08f64393985215ba6e59171e","3402fc06712244c6af566b454f7765cb","e592d13cae9b43ec9a342816b6f11621","0690ad87b5914cc3ae4793d30d7d5e0f","3bec4bae60a7457eaf8686882761eccf","eb14099137f4498aae252c528dfe0635","98cfde9814544668a568372826e81994","51a7f78cd79e41f8abfd545edd1b411d","0f392ae8c3874c1aa9bf161e124e8ca1","cf1fa6ea88554220991928cdf35d384b","c17239edab094cfe87e18fc5b7889929","101a19bc18454597b3babd9708cc33dd","e90b4cd158384f3e9e64c4b581f8a441","83de77b3c88c404fac8618836e9b929d","0cc59721d6c44ef6b4f865aa358b76af","f9ae365d047f45b8b4878d9057766448","b053e35c9e1c45e39b3aec2cd94dde42","ad5bbc34a4f34ff89d3832eb8fb75775","506de4cccf914574a6e16b816c2287fa","192982fb3a934d0595c44c2d8abbcd5b","d893334e4cfe467da570316256336cdc","96d37264fbab4436b3a86041338bd386","2dd1a8e2c4b24dab81fdb0bb28ae86c1","77d0094576b4428c927d9755f6c4bbab","fcc53c9c420846e68bb117a9337a62ed","efb324f821da4bdd8de768f1fe0eddca","f55c4dd56e7f457a9e0bdfcf5eda8883","4c78b375a65b4ee5b56dad6d40e2c087","e535633230874775ae0fdfa5fc56faa7","e20978016e974e4a8bf76dfb9fe3794b","85d554f3098348849832b19f85dbd804","1bc91d25aa4047ed8f1028966529bc39","50f9ce2b998148b99787602d6e9b0291","df7a0796d1fc44a8b73729cece4d65e7","4e9bcbcfbf6448f0a38d2c6f6475d425","f82a308456ec40df93a1352840efdebf","9397caf95f4b40569cd07e1aae27d210","bbd29fac9d4f489dba1488042e1f1864","c984413f875b4a7b896f1d9971f3f40c","19bc695a0eae4e01b6c5d73ab5dbbd88","17651c5754f2464d9f0aa3cf4f9b2c59","8084712258534cd8bc59bb5f47377a03","0d64a132b45844edac1059c4a867bad8","fde8e611da7249ed8127db2a26f23ad3","e336e3d8618a439296419cbb5957e8c8","259f18283e9843bc86871b3cf02a1e2a","0b21912d11f84f05970351739b13c737"]},"id":"Q5xi1k65IbvB","executionInfo":{"status":"ok","timestamp":1705557312368,"user_tz":-540,"elapsed":11948,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"901ace9b-e72b-4c7c-fc05-3ab385c67ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/282 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69d370fe94c148b5b4bfba841de38a42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["spiece.model:   0%|          | 0.00/806k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0690ad87b5914cc3ae4793d30d7d5e0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/153 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cc59721d6c44ef6b4f865aa358b76af"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"efb324f821da4bdd8de768f1fe0eddca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/454M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9397caf95f4b40569cd07e1aae27d210"}},"metadata":{}}]},{"cell_type":"markdown","source":["## 専用トークンの追加"],"metadata":{"id":"Od6fSb5PI0Yr"}},{"cell_type":"code","source":["print(f\"トークン追加前: {len(tokenizer)=}, {len(tokenizer.all_special_tokens)=}\")\n","print(tokenizer.all_special_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JDqZpBbnIxFm","executionInfo":{"status":"ok","timestamp":1705557346508,"user_tz":-540,"elapsed":7,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"ae3c6349-537d-46f4-efac-7f616d8a2a6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["トークン追加前: len(tokenizer)=32000, len(tokenizer.all_special_tokens)=7\n","['<s>', '</s>', '<unk>', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"]}]},{"cell_type":"code","source":["# 専用トークン追加\n","special_tokens = {\n","    \"additional_special_tokens\": [\"<NEG_START>\", \"<POS_START>\"]\n","}\n","\n","tokenizer.add_special_tokens(special_tokens)\n","print(f\"トークン追加後: {len(tokenizer)=}, {len(tokenizer.all_special_tokens)=}\")\n","print(tokenizer.all_special_tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l9ux_W7FI8Vn","executionInfo":{"status":"ok","timestamp":1705557378748,"user_tz":-540,"elapsed":6,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"a50abfce-75d3-4a82-aec5-c2d646a04cff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["トークン追加後: len(tokenizer)=32002, len(tokenizer.all_special_tokens)=9\n","['<s>', '</s>', '<unk>', '[SEP]', '[PAD]', '[CLS]', '[MASK]', '<NEG_START>', '<POS_START>']\n"]}]},{"cell_type":"code","source":["# トークナイザー保存\n","tokenizer.save_pretrained(\"reframing_tokenizer.pt\")\n","\n","# 追加した専用トークン用のembeddingsを用意\n","model.resize_token_embeddings(len(tokenizer))\n","\n","# モデル保存\n","model.save_pretrained(\"model/reframing_model\")"],"metadata":{"id":"G-agXjbZJEL0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## データの準備"],"metadata":{"id":"JBGVsBhaJJJV"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# リフレーミングコーパスのロード\n","dir_path = \"drive/MyDrive/ColabNotebooks/nallab/t5/\"\n","excel_file_path = \"drive/MyDrive/ColabNotebooks/nallab/corpus/reframing-corpus.xlsx\"\n","sheet_name = \"発話\"\n","corpus_df = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n","corpus_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"zJ1fqt3SJH0R","executionInfo":{"status":"ok","timestamp":1705557413167,"user_tz":-540,"elapsed":2054,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"83663a88-f31c-455b-e13f-e72cb2e7bc69"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        No  ペルソナID 話者   トピック                                               発話\n","0        1       1  A   生活全般        最近同じ日常の繰り返しで、新しいことを始める勇気が出なくてモヤモヤしているんです。\n","1        1       1  B   生活全般  落ち着いた生活を送りながら新しいことを始めようとするあなたはチャレンジ精神が素晴らしいですね。\n","2        2       1  A  職場・学業            生徒たちにもっとわかりやすく教えたいのに、伝わってない気がして悔しいです。\n","3        2       1  B  職場・学業      あなたは生徒たちの理解を深く気にかけ、より良い指導を心がけている素晴らしい教師ですね。\n","4        3       1  A  家族・恋愛       両親にもっと近くに住みたいって言われるけど、自分の仕事や生活を考えると複雑なんです。\n","...    ...     ... ..    ...                                              ...\n","1995   998     250  B  職場・学業                    好きなことを仕事にできていることはとても素敵なことですね。\n","1996   999     250  A  家族・恋愛              夫とは長い間一緒にいるけれど、最近は会話が少なくなってきて寂しいです。\n","1997   999     250  B  家族・恋愛              いつまでも旦那さんとの会話を大切にしているあなたは素敵な奥さんですね。\n","1998  1000     250  A   自己評価            自分は家族や仕事を大切にしてきたけど、それが十分だったのか疑問に思います。\n","1999  1000     250  B   自己評価                    家族や仕事を大切にしてきたと言えることが素晴らしいですね。\n","\n","[2000 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-59680c0e-ac44-43d8-b35e-628ae5ae8d5d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No</th>\n","      <th>ペルソナID</th>\n","      <th>話者</th>\n","      <th>トピック</th>\n","      <th>発話</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>生活全般</td>\n","      <td>最近同じ日常の繰り返しで、新しいことを始める勇気が出なくてモヤモヤしているんです。</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>生活全般</td>\n","      <td>落ち着いた生活を送りながら新しいことを始めようとするあなたはチャレンジ精神が素晴らしいですね。</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>職場・学業</td>\n","      <td>生徒たちにもっとわかりやすく教えたいのに、伝わってない気がして悔しいです。</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>B</td>\n","      <td>職場・学業</td>\n","      <td>あなたは生徒たちの理解を深く気にかけ、より良い指導を心がけている素晴らしい教師ですね。</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>A</td>\n","      <td>家族・恋愛</td>\n","      <td>両親にもっと近くに住みたいって言われるけど、自分の仕事や生活を考えると複雑なんです。</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1995</th>\n","      <td>998</td>\n","      <td>250</td>\n","      <td>B</td>\n","      <td>職場・学業</td>\n","      <td>好きなことを仕事にできていることはとても素敵なことですね。</td>\n","    </tr>\n","    <tr>\n","      <th>1996</th>\n","      <td>999</td>\n","      <td>250</td>\n","      <td>A</td>\n","      <td>家族・恋愛</td>\n","      <td>夫とは長い間一緒にいるけれど、最近は会話が少なくなってきて寂しいです。</td>\n","    </tr>\n","    <tr>\n","      <th>1997</th>\n","      <td>999</td>\n","      <td>250</td>\n","      <td>B</td>\n","      <td>家族・恋愛</td>\n","      <td>いつまでも旦那さんとの会話を大切にしているあなたは素敵な奥さんですね。</td>\n","    </tr>\n","    <tr>\n","      <th>1998</th>\n","      <td>1000</td>\n","      <td>250</td>\n","      <td>A</td>\n","      <td>自己評価</td>\n","      <td>自分は家族や仕事を大切にしてきたけど、それが十分だったのか疑問に思います。</td>\n","    </tr>\n","    <tr>\n","      <th>1999</th>\n","      <td>1000</td>\n","      <td>250</td>\n","      <td>B</td>\n","      <td>自己評価</td>\n","      <td>家族や仕事を大切にしてきたと言えることが素晴らしいですね。</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2000 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59680c0e-ac44-43d8-b35e-628ae5ae8d5d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-59680c0e-ac44-43d8-b35e-628ae5ae8d5d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-59680c0e-ac44-43d8-b35e-628ae5ae8d5d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-dd4910d0-d28c-40e5-a65d-a83c1982e082\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd4910d0-d28c-40e5-a65d-a83c1982e082')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-dd4910d0-d28c-40e5-a65d-a83c1982e082 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_7e25931f-a2c7-49f8-b1f9-98aab5f9793c\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('corpus_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_7e25931f-a2c7-49f8-b1f9-98aab5f9793c button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('corpus_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 話者Aのネガティブ発話(偶数行)だけ取り出す\n","even_indices = corpus_df.index % 2 == 0\n","even_rows_df = corpus_df[even_indices].copy()\n","\n","negative_texts = []\n","for i in range(len(even_rows_df)):\n","  negative_text = even_rows_df.iloc[i, 4]\n","  negative_texts.append(negative_text)\n","\n","# 話者Bのポジティブ発話(奇数行)だけ取り出す\n","odd_indices = corpus_df.index % 2 != 0\n","odd_rows_df = corpus_df[odd_indices].copy()\n","\n","positive_texts = []\n","for i in range(len(odd_rows_df)):\n","  positive_text = odd_rows_df.iloc[i, 4]\n","  positive_texts.append(positive_text)"],"metadata":{"id":"jUzwjJUtJMFz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# データ整形\n","corpus_sentences = []\n","for sentence_i in range(len(even_rows_df)):\n","    data = '<NEG_START>' + negative_texts[sentence_i] + '<POS_START>' + positive_texts[sentence_i] + '</s>'\n","    corpus_sentences.append(data)\n","\n","# ランダムにシャッフル\n","import random\n","random.shuffle(corpus_sentences)\n","\n","# データを8:1:1の比率で分割\n","total_len = len(corpus_sentences)\n","split_index_1 = int(0.8 * total_len)\n","split_index_2 = split_index_1 + int(0.1 * total_len)\n","\n","learning_data = corpus_sentences[:split_index_1]\n","validation_data = corpus_sentences[split_index_1:split_index_2]\n","test_data = corpus_sentences[split_index_2:]\n","\n","# ラーニングデータの書き出し\n","with open('data/train.txt', 'w') as learning_data_file:\n","    learning_data_file.write('\\n'.join(learning_data) + '\\n')\n","\n","# 検証データの書き出し\n","with open('data/val.txt', 'w') as validation_data_file:\n","    validation_data_file.write('\\n'.join(validation_data) + '\\n')\n","\n","# テストデータの書き出し\n","with open('data/test.txt', 'w') as test_data_file:\n","    test_data_file.write('\\n'.join(test_data) + '\\n')\n","\n","print(f\"{len(learning_data)=}, {len(validation_data)=}, {len(test_data)=}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QiNvepnJPHq","executionInfo":{"status":"ok","timestamp":1705557684522,"user_tz":-540,"elapsed":455,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"cd1d0ddd-b3ac-4990-c407-1808a6e55ad0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len(learning_data)=800, len(validation_data)=100, len(test_data)=100\n"]}]},{"cell_type":"markdown","source":["## ハイパーパラメータチューニング (対象：epoch数)"],"metadata":{"id":"_D9QcYj8KTHo"}},{"cell_type":"code","source":["import os\n","from sklearn.model_selection import KFold\n","\n","with open(\"data/train.txt\", \"r\") as f:\n","    lines = f.readlines()\n","\n","# 交差検証の設定\n","kf = KFold(n_splits=5, shuffle=True, random_state=42)\n","\n","for fold, (train_idx, val_idx) in enumerate(kf.split(lines), start=1):\n","    train_lines = [lines[i] for i in train_idx]\n","    val_lines = [lines[i] for i in val_idx]\n","\n","    # 訓練データと検証データの保存先ディレクトリ\n","    train_val_dir = f\"data/fold_{fold}\"\n","    os.makedirs(train_val_dir, exist_ok=True)\n","\n","    # 訓練データと検証データをテキストファイルとして保存\n","    train_file = f\"data/fold_{fold}/train.txt\"\n","    val_file = f\"data/fold_{fold}/val.txt\"\n","    with open(train_file, \"w\") as f:\n","        f.writelines(train_lines)\n","    with open(val_file, \"w\") as f:\n","        f.writelines(val_lines)"],"metadata":{"id":"G-MIrIlSKOvN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tuning_epoch_output_path = \"outputs/epochs\"\n","if not os.path.exists(tuning_epoch_output_path):\n","    os.makedirs(tuning_epoch_output_path)"],"metadata":{"id":"u-86oOJ9P10K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import os\n","\n","# 初期エポック数\n","epochs = 1\n","\n","overfitting_count = 0\n","patience = 1\n","\n","average_train_losses = []\n","average_val_losses = []\n","\n","while overfitting_count < patience:\n","\n","    # 一時的にlossとaccuracyを記録\n","    train_losses = []\n","    val_losses = []\n","\n","    for fold in range(1, 6):\n","        train_file = f\"data/fold_{fold}/train.txt\"\n","        val_file = f\"data/fold_{fold}/val.txt\"\n","        output_dir = f\"{tuning_epoch_output_path}/{epochs}_output_fold_{fold}\"\n","\n","        # ファインチューニングを実行\n","        os.system(f\"\"\"\n","        python ./transformers/examples/pytorch/language-modeling/run_clm.py \\\n","            --model_name_or_path='model/reframing_model' \\\n","            --tokenizer_name='reframing_tokenizer.pt' \\\n","            --train_file={train_file} \\\n","            --validation_file={val_file} \\\n","            --do_train \\\n","            --do_eval \\\n","            --num_train_epochs={epochs} \\\n","            --save_steps=10000 \\\n","            --save_total_limit=3 \\\n","            --per_device_train_batch_size=1 \\\n","            --per_device_eval_batch_size=1 \\\n","            --use_fast_tokenizer=False \\\n","            --output_dir={output_dir}\n","        \"\"\")\n","        print(f\"Epochs: {epochs}, Fold: {fold}\")\n","\n","        # train_results.jsonからlossを取得してリストに追加\n","        with open(os.path.join(output_dir, \"train_results.json\")) as train_file, open(os.path.join(output_dir, \"eval_results.json\")) as val_file:\n","            train_results = json.load(train_file)\n","            val_results = json.load(val_file)\n","            train_loss = train_results[\"train_loss\"]\n","            val_loss = val_results[\"eval_loss\"]\n","            train_losses.append(train_loss)\n","            val_losses.append(val_loss)\n","\n","    # 各エポック数ごとのlossの平均を計算\n","    avg_train_losses = sum(train_losses)/len(train_losses)\n","    avg_val_losses = sum(val_losses)/len(val_losses)\n","    print(f\"Epochs: {epochs}, Average Train Loss: {avg_train_losses}, Average Validation Loss: {avg_val_losses}\")\n","\n","    # early-stopping\n","    # train_lossは下がったがeval_lossesが上がった場合\n","    if len(average_train_losses) > 1 and len(average_val_losses) > 1:\n","        if avg_train_losses < average_train_losses[-1] and avg_val_losses > average_val_losses[-1]:\n","            overfitting_count += 1\n","\n","    average_train_losses.append(avg_train_losses)\n","    average_val_losses.append(avg_val_losses)\n","\n","    # 一時記録用のリストを初期化\n","    train_losses.clear()\n","    val_losses.clear()\n","\n","    epochs += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ElQ-F5FRKoY2","executionInfo":{"status":"ok","timestamp":1705560346552,"user_tz":-540,"elapsed":1104792,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"70e64ed8-90ea-426f-e356-e9189f15fa20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epochs: 1, Fold: 1\n","Epochs: 1, Fold: 2\n","Epochs: 1, Fold: 3\n","Epochs: 1, Fold: 4\n","Epochs: 1, Fold: 5\n","Epochs: 1, Average Train Loss: 2.6986489068894155, Average Validation Loss: 2.309105968475342\n","Epochs: 2, Fold: 1\n","Epochs: 2, Fold: 2\n","Epochs: 2, Fold: 3\n","Epochs: 2, Fold: 4\n","Epochs: 2, Fold: 5\n","Epochs: 2, Average Train Loss: 2.256475103469122, Average Validation Loss: 1.8296225786209106\n","Epochs: 3, Fold: 1\n","Epochs: 3, Fold: 2\n","Epochs: 3, Fold: 3\n","Epochs: 3, Fold: 4\n","Epochs: 3, Fold: 5\n","Epochs: 3, Average Train Loss: 1.9817346239846851, Average Validation Loss: 1.6803311109542847\n","Epochs: 4, Fold: 1\n","Epochs: 4, Fold: 2\n","Epochs: 4, Fold: 3\n","Epochs: 4, Fold: 4\n","Epochs: 4, Fold: 5\n","Epochs: 4, Average Train Loss: 1.799665360223679, Average Validation Loss: 1.6073632478713988\n","Epochs: 5, Fold: 1\n","Epochs: 5, Fold: 2\n","Epochs: 5, Fold: 3\n","Epochs: 5, Fold: 4\n","Epochs: 5, Fold: 5\n","Epochs: 5, Average Train Loss: 1.6609653145926342, Average Validation Loss: 1.5667062997817993\n","Epochs: 6, Fold: 1\n","Epochs: 6, Fold: 2\n","Epochs: 6, Fold: 3\n","Epochs: 6, Fold: 4\n","Epochs: 6, Fold: 5\n","Epochs: 6, Average Train Loss: 1.5482222057524182, Average Validation Loss: 1.545432162284851\n","Epochs: 7, Fold: 1\n","Epochs: 7, Fold: 2\n","Epochs: 7, Fold: 3\n","Epochs: 7, Fold: 4\n","Epochs: 7, Fold: 5\n","Epochs: 7, Average Train Loss: 1.4529456313775508, Average Validation Loss: 1.5359985828399658\n","Epochs: 8, Fold: 1\n","Epochs: 8, Fold: 2\n","Epochs: 8, Fold: 3\n","Epochs: 8, Fold: 4\n","Epochs: 8, Fold: 5\n","Epochs: 8, Average Train Loss: 1.3705494835263206, Average Validation Loss: 1.5341849088668824\n","Epochs: 9, Fold: 1\n","Epochs: 9, Fold: 2\n","Epochs: 9, Fold: 3\n","Epochs: 9, Fold: 4\n","Epochs: 9, Fold: 5\n","Epochs: 9, Average Train Loss: 1.2970085830284803, Average Validation Loss: 1.5375986099243164\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# 平均トレーニング損失とバリデーション損失のデータ\n","average_train_losses = [2.6986489068894155, 2.256475103469122, 1.9817346239846851,\n","                        1.799665360223679, 1.6609653145926342, 1.5482222057524182,\n","                        1.4529456313775508, 1.3705494835263206, 1.2970085830284803]\n","average_val_losses = [2.309105968475342, 1.8296225786209106, 1.6803311109542847,\n","                      1.6073632478713988, 1.5667062997817993, 1.545432162284851,\n","                      1.5359985828399658, 1.5341849088668824, 1.5375986099243164]\n","\n","epochs = list(range(1, 10))\n","\n","plt.figure(figsize=(10, 6))\n","plt.plot(epochs, average_train_losses, label='Average Train Loss', color='skyblue')\n","plt.plot(epochs, average_val_losses, label='Average Val Loss', color='orange')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"xF_1LuA_O-hY","executionInfo":{"status":"ok","timestamp":1705754084256,"user_tz":-540,"elapsed":1014,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"e89cb7f5-9685-42a7-964f-799c9aa95621"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## ファインチューニング"],"metadata":{"id":"gPCsLM86XqYN"}},{"cell_type":"code","source":["# ファインチューニングを実行\n","!python ./transformers/examples/pytorch/language-modeling/run_clm.py \\\n","    --model_name_or_path=\"model/reframing_model\" \\\n","    --tokenizer_name=\"reframing_tokenizer.pt\" \\\n","    --train_file=\"data/train.txt\" \\\n","    --validation_file=\"data/val.txt\" \\\n","    --do_train \\\n","    --do_eval \\\n","    --num_train_epochs=8 \\\n","    --learning_rate=5e-05 \\\n","    --save_steps=10000 \\\n","    --save_total_limit=3 \\\n","    --per_device_train_batch_size=1 \\\n","    --per_device_eval_batch_size=1 \\\n","    --overwrite_output_dir \\\n","    --use_fast_tokenizer=False \\\n","    --output_dir={MODEL_DIR}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f5PTgzKGXYRe","executionInfo":{"status":"ok","timestamp":1705561306582,"user_tz":-540,"elapsed":36775,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"f2776aed-8d97-4e8f-9521-731a6350f477"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-01-18 07:01:13.226796: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-01-18 07:01:13.226846: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-01-18 07:01:13.228279: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-01-18 07:01:14.402250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","CUDA backend failed to initialize: Found cuBLAS version 120103, but JAX was built against version 120205, which is newer. The copy of cuBLAS that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n","01/18/2024 07:01:16 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: False\n","01/18/2024 07:01:16 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_persistent_workers=False,\n","dataloader_pin_memory=True,\n","ddp_backend=None,\n","ddp_broadcast_buffers=None,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","dispatch_batches=None,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","gradient_checkpointing_kwargs=None,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_always_push=False,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","include_num_input_tokens_seen=False,\n","include_tokens_per_second=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=0,\n","log_level=passive,\n","log_level_replica=warning,\n","log_on_each_node=True,\n","logging_dir=model/final_output/runs/Jan18_07-01-16_10e2f779eb6d,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_kwargs={},\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","neftune_noise_alpha=None,\n","no_cuda=False,\n","num_train_epochs=8.0,\n","optim=adamw_torch,\n","optim_args=None,\n","output_dir=model/final_output,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=1,\n","per_device_train_batch_size=1,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=model/final_output,\n","save_on_each_node=False,\n","save_only_model=False,\n","save_safetensors=True,\n","save_steps=10000,\n","save_strategy=steps,\n","save_total_limit=3,\n","seed=42,\n","skip_memory_metrics=True,\n","split_batches=False,\n","tf32=None,\n","torch_compile=False,\n","torch_compile_backend=None,\n","torch_compile_mode=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_cpu=False,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n",")\n","Using custom data configuration default-af3ef647903b953b\n","01/18/2024 07:01:17 - INFO - datasets.builder - Using custom data configuration default-af3ef647903b953b\n","Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n","01/18/2024 07:01:17 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.10/dist-packages/datasets/packaged_modules/text\n","Generating dataset text (/root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n","01/18/2024 07:01:17 - INFO - datasets.builder - Generating dataset text (/root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34)\n","Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34...\n","01/18/2024 07:01:17 - INFO - datasets.builder - Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34...\n","Downloading took 0.0 min\n","01/18/2024 07:01:17 - INFO - datasets.download.download_manager - Downloading took 0.0 min\n","Checksum Computation took 0.0 min\n","01/18/2024 07:01:17 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min\n","Generating train split\n","01/18/2024 07:01:17 - INFO - datasets.builder - Generating train split\n","Generating train split: 800 examples [00:00, 87515.80 examples/s]\n","Generating validation split\n","01/18/2024 07:01:17 - INFO - datasets.builder - Generating validation split\n","Generating validation split: 100 examples [00:00, 90648.45 examples/s]\n","Unable to verify splits sizes.\n","01/18/2024 07:01:17 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34. Subsequent calls will reuse this data.\n","01/18/2024 07:01:17 - INFO - datasets.builder - Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34. Subsequent calls will reuse this data.\n","[INFO|configuration_utils.py:727] 2024-01-18 07:01:17,299 >> loading configuration file model/reframing_model/config.json\n","[INFO|configuration_utils.py:792] 2024-01-18 07:01:17,300 >> Model config GPT2Config {\n","  \"_name_or_path\": \"model/reframing_model\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 1,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": 3072,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.37.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 32002\n","}\n","\n","[INFO|tokenization_utils_base.py:2025] 2024-01-18 07:01:17,301 >> loading file spiece.model\n","[INFO|tokenization_utils_base.py:2025] 2024-01-18 07:01:17,301 >> loading file added_tokens.json\n","[INFO|tokenization_utils_base.py:2025] 2024-01-18 07:01:17,301 >> loading file special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2025] 2024-01-18 07:01:17,301 >> loading file tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2025] 2024-01-18 07:01:17,301 >> loading file tokenizer.json\n","[WARNING|logging.py:314] 2024-01-18 07:01:17,488 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|modeling_utils.py:3465] 2024-01-18 07:01:17,492 >> loading weights file model/reframing_model/model.safetensors\n","[INFO|configuration_utils.py:826] 2024-01-18 07:01:17,499 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2\n","}\n","\n","[INFO|modeling_utils.py:4342] 2024-01-18 07:01:17,850 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","[INFO|modeling_utils.py:4350] 2024-01-18 07:01:17,850 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at model/reframing_model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","[INFO|configuration_utils.py:779] 2024-01-18 07:01:17,852 >> loading configuration file model/reframing_model/generation_config.json\n","[INFO|configuration_utils.py:826] 2024-01-18 07:01:17,852 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 1,\n","  \"eos_token_id\": 2\n","}\n","\n","Running tokenizer on dataset:   0% 0/800 [00:00<?, ? examples/s]/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:303: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n","  warnings.warn(\n","Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-5580b0a860c26b4d.arrow\n","01/18/2024 07:01:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-5580b0a860c26b4d.arrow\n","Running tokenizer on dataset: 100% 800/800 [00:00<00:00, 5740.65 examples/s]\n","Running tokenizer on dataset:   0% 0/100 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-15b55b482c7f1ec1.arrow\n","01/18/2024 07:01:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-15b55b482c7f1ec1.arrow\n","Running tokenizer on dataset: 100% 100/100 [00:00<00:00, 4613.54 examples/s]\n","01/18/2024 07:01:18 - WARNING - __main__ - The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Using block_size=1024 instead. You can change that default value by passing --block_size xxx.\n","Grouping texts in chunks of 1024:   0% 0/800 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-93119e89fac5af05.arrow\n","01/18/2024 07:01:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-93119e89fac5af05.arrow\n","Grouping texts in chunks of 1024: 100% 800/800 [00:00<00:00, 19473.86 examples/s]\n","Grouping texts in chunks of 1024:   0% 0/100 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-a432a7973c4eae99.arrow\n","01/18/2024 07:01:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/text/default-af3ef647903b953b/0.0.0/c4a140d10f020282918b5dd1b8a49f0104729c6177f60a6b49ec2a365ec69f34/cache-a432a7973c4eae99.arrow\n","Grouping texts in chunks of 1024: 100% 100/100 [00:00<00:00, 11301.75 examples/s]\n","[INFO|trainer.py:1721] 2024-01-18 07:01:19,463 >> ***** Running training *****\n","[INFO|trainer.py:1722] 2024-01-18 07:01:19,463 >>   Num examples = 26\n","[INFO|trainer.py:1723] 2024-01-18 07:01:19,463 >>   Num Epochs = 8\n","[INFO|trainer.py:1724] 2024-01-18 07:01:19,463 >>   Instantaneous batch size per device = 1\n","[INFO|trainer.py:1727] 2024-01-18 07:01:19,463 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n","[INFO|trainer.py:1728] 2024-01-18 07:01:19,463 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1729] 2024-01-18 07:01:19,463 >>   Total optimization steps = 208\n","[INFO|trainer.py:1730] 2024-01-18 07:01:19,463 >>   Number of trainable parameters = 110,419,968\n","100% 208/208 [00:24<00:00,  8.87it/s][INFO|trainer.py:1962] 2024-01-18 07:01:43,778 >> \n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","{'train_runtime': 24.3209, 'train_samples_per_second': 8.552, 'train_steps_per_second': 8.552, 'train_loss': 1.3144610478327825, 'epoch': 8.0}\n","100% 208/208 [00:24<00:00,  8.55it/s]\n","[INFO|trainer.py:2910] 2024-01-18 07:01:43,786 >> Saving model checkpoint to model/final_output\n","[INFO|configuration_utils.py:473] 2024-01-18 07:01:43,788 >> Configuration saved in model/final_output/config.json\n","[INFO|configuration_utils.py:594] 2024-01-18 07:01:43,788 >> Configuration saved in model/final_output/generation_config.json\n","[INFO|modeling_utils.py:2485] 2024-01-18 07:01:44,631 >> Model weights saved in model/final_output/model.safetensors\n","[INFO|tokenization_utils_base.py:2433] 2024-01-18 07:01:44,632 >> tokenizer config file saved in model/final_output/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2442] 2024-01-18 07:01:44,632 >> Special tokens file saved in model/final_output/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2493] 2024-01-18 07:01:44,632 >> added tokens file saved in model/final_output/added_tokens.json\n","***** train metrics *****\n","  epoch                    =        8.0\n","  train_loss               =     1.3145\n","  train_runtime            = 0:00:24.32\n","  train_samples            =         26\n","  train_samples_per_second =      8.552\n","  train_steps_per_second   =      8.552\n","01/18/2024 07:01:44 - INFO - __main__ - *** Evaluate ***\n","[INFO|trainer.py:3216] 2024-01-18 07:01:44,637 >> ***** Running Evaluation *****\n","[INFO|trainer.py:3218] 2024-01-18 07:01:44,637 >>   Num examples = 3\n","[INFO|trainer.py:3221] 2024-01-18 07:01:44,637 >>   Batch size = 1\n","100% 3/3 [00:00<00:00, 33.72it/s]\n","***** eval metrics *****\n","  epoch                   =        8.0\n","  eval_accuracy           =     0.6628\n","  eval_loss               =     1.5229\n","  eval_runtime            = 0:00:00.12\n","  eval_samples            =          3\n","  eval_samples_per_second =     23.232\n","  eval_steps_per_second   =     23.232\n","  perplexity              =     4.5855\n","[INFO|modelcard.py:452] 2024-01-18 07:01:44,944 >> Dropping the following result as it does not have all the necessary fields:\n","{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}, 'metrics': [{'name': 'Accuracy', 'type': 'accuracy', 'value': 0.6627565982404692}]}\n"]}]},{"cell_type":"markdown","source":["## 評価実験"],"metadata":{"id":"XoDuif4mYcp2"}},{"cell_type":"code","source":["from pathlib import Path\n","import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# トークナイザーをロード\n","tokenizer_path = \"reframing_tokenizer.pt\"\n","tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n","tokenizer.do_lower_case = True\n","\n","# ファインチューニング済みモデルをロード\n","model = AutoModelForCausalLM.from_pretrained(MODEL_DIR)\n","model.to(device)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XkSpTUQtYT03","executionInfo":{"status":"ok","timestamp":1705561550394,"user_tz":-540,"elapsed":864,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"d151066f-de8f-4274-ab16-f6dfe4b2b8e1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(32002, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32002, bias=False)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["tokenizer_with_prefix_space = T5Tokenizer.from_pretrained(tokenizer_path, add_prefix_space=True)\n","\n","# トークンIDを取得する関数\n","def get_tokens_as_list(word_list):\n","    tokens_list = []\n","    for word in word_list:\n","        tokenized_word = tokenizer_with_prefix_space([word], add_special_tokens=False).input_ids[0]\n","        tokens_list.append(tokenized_word)\n","    return tokens_list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpvIoAFxY-bJ","executionInfo":{"status":"ok","timestamp":1705561580686,"user_tz":-540,"elapsed":377,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"26da3a81-8d3b-4e7b-c0d3-a23e0dac4ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["bad_words_ids = get_tokens_as_list(word_list=[\"<s>\", \"</s>\", \"<unk>\", \"[SEP]\", \"[PAD]\", \"[CLS]\", \"[MASK]\", \"<POS_START>\", \"<NEG_START>\", \"...\", \"_\", \"|\", \".\", \":\", \";\", \"{}\", \"{\", \"}\", \"()\", \"(\", \")\", \"[]\", \"[\", \"]\", '\"\"', \"codice\", \"太守\"])\n","\n","# 返答を生成する関数(ビームサーチ)\n","def generate_reply_beam(inp, num_gen=100):\n","    input_text = \"<s>\" + str(inp) + \"[SEP]\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='pt', padding=True, truncation=True).to(device)\n","\n","    num_beams = num_gen\n","    out = model.generate(input_ids, max_length=64, num_beams=num_beams,\n","                         num_return_sequences=num_gen, no_repeat_ngram_size=3,\n","                         bos_token_id=tokenizer.bos_token_id, eos_token_id=tokenizer.eos_token_id,\n","                         bad_words_ids=bad_words_ids)\n","\n","    replies = []\n","    for sent in tokenizer.batch_decode(out):\n","        sent = sent.split('[SEP]</s>')[1]\n","        sent = sent.replace('</s>', '')\n","        sent = sent.replace('<br>', '\\n')\n","        replies.append(sent.strip())\n","\n","    # 生成確率が最も高い返答文\n","    top_reply = replies[0]\n","\n","    return replies, top_reply"],"metadata":{"id":"kqSUS95lZF5Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_parts(text):\n","    \"\"\" '<NEG_START>' から '<POS_START>' までと '<POS_START>' から '</s>' までの部分を抽出 \"\"\"\n","    input_text = text.split(\"<POS_START>\")[0].split(\"<NEG_START>\")[1].strip()\n","    correct_reply = text.split(\"<POS_START>\")[1].split(\"</s>\")[0].strip()\n","    return input_text, correct_reply"],"metadata":{"id":"5UZaH02CZNHU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import MeCab\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","def tokenize_japanese(text):\n","    m = MeCab.Tagger(\"-Owakati\")\n","    return m.parse(text).strip().split()\n","\n","# BLEUを計算する関数\n","def calculate_bleu_score(reference, candidate):\n","    reference_tokenized = [tokenize_japanese(reference)]\n","    candidate_tokenized = tokenize_japanese(candidate)\n","    score = sentence_bleu(reference_tokenized, candidate_tokenized, weights=(0.5, 0.5))  # Bigrams\n","    return score"],"metadata":{"id":"wIWqAK0PZQO5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","# 生成確率の最も高い返答文のベクトル化する関数\n","def vectorization(top_reply):\n","  tokenized_top_reply = tokenizer(top_reply, return_tensors='pt', padding=True, truncation=True).to(device)\n","  # モデルを通して特徴ベクトルを生成\n","  with torch.inference_mode():\n","      outputs = model(**tokenized_top_reply, output_hidden_states=True)\n","      # 最後の隠れ層の状態を取得\n","      last_hidden_state = outputs.hidden_states[-1]\n","      # 平均プーリング\n","      top_reply_vector = last_hidden_state.mean(dim=1).to(\"cpu\")\n","  # ベクトルをノルムが1になるよう正規化\n","  top_reply_vector = F.normalize(top_reply_vector, dim=1)\n","  torch.linalg.norm(top_reply_vector, dim=1)\n","  return top_reply_vector"],"metadata":{"id":"vIuUBaMjZSZm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 生成確率の最も高い返答文と正解返答文のコサイン類似度を計算する関数\n","def cosine_similarity(vec1, vec2):\n","    # ベクトルがノルム1に正規化されているため、ドット積を計算\n","    # vec1とvec2が2次元テンソルで1 x Nの形状の場合、それらを1次元に変換\n","    vec1 = vec1.squeeze()\n","    vec2 = vec2.squeeze()\n","    return torch.dot(vec1, vec2)"],"metadata":{"id":"62Rs1cVAZW6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calculate_accuracy_beam(test_data):\n","    correct_count = 0\n","    total_mrr = 0\n","    total_bleu = 0\n","    total_similarity = 0\n","    max_bleu_scores = []\n","    max_similarity_scores = []\n","    correct_replies_dict = {}\n","    top_reply_dict = {}\n","\n","    for index, data in enumerate(test_data):\n","        input_text, correct_reply = extract_parts(data)\n","        replies, top_reply = generate_reply_beam(input_text)\n","        top_reply_dict[index] = {\"input_text\": input_text, \"top_reply\": top_reply}\n","\n","        max_bleu_score = 0\n","        max_similarity_score = 0\n","\n","        # 正解データのベクトル化\n","        correct_reply_vector = vectorization(correct_reply)\n","\n","        for reply in replies:\n","            # BLEUスコアの計算\n","            bleu_score = calculate_bleu_score(correct_reply, reply)\n","            max_bleu_score = max(max_bleu_score, bleu_score)\n","\n","            # 返答文のベクトル化\n","            reply_vector = vectorization(reply)\n","\n","            # コサイン類似度の計算\n","            similarity = cosine_similarity(correct_reply_vector, reply_vector)\n","            max_similarity_score = max(max_similarity_score, similarity)\n","\n","        max_bleu_scores.append(max_bleu_score)\n","        max_similarity_scores.append(max_similarity_score)\n","\n","        # 正解文が返答候補の中にあるか確認\n","        if correct_reply in replies:\n","            rank = replies.index(correct_reply) + 1\n","            correct_replies_dict[index] = {\n","                \"rank\": rank,\n","                \"input_text\": input_text,\n","                \"correct_reply\": correct_reply\n","            }\n","            correct_count += 1\n","            # MRRの計算\n","            total_mrr += 1 / rank\n","\n","        # 最も生成確率が高い返答のBLEUスコアの計算\n","        bleu_score = calculate_bleu_score(correct_reply, top_reply)\n","        total_bleu += bleu_score\n","\n","        # 生成確率の最も高い返答文のベクトル化\n","        top_reply_vector = vectorization(top_reply)\n","\n","        # コサイン類似度の計算\n","        similarity = cosine_similarity(correct_reply_vector, top_reply_vector)\n","        total_similarity += similarity\n","\n","    # 正解が含まれている割合（精度：Acc）の計算\n","    accuracy = correct_count / len(test_data)\n","\n","    # MRRの計算\n","    mrr = total_mrr / len(test_data)\n","\n","    # 平均BLEUスコアの計算\n","    average_bleu = total_bleu / len(test_data)\n","\n","    # 平均コサイン類似度の計算\n","    average_similarity = total_similarity / len(test_data)\n","\n","    # 最大BLEUスコアと最大コサイン類似度の平均を計算\n","    average_max_bleu = sum(max_bleu_scores) / len(test_data)\n","    average_max_similarity = sum(max_similarity_scores) / len(test_data)\n","\n","    return accuracy, mrr, average_bleu, average_similarity, average_max_bleu, average_max_similarity, correct_replies_dict, top_reply_dict\n","\n","# 実行\n","acc, mrr, average_bleu, average_similarity, max_bleu, max_similarity, correct_replies_dict, top_reply_dict = calculate_accuracy_beam(test_data)\n","print(f\"Accuracy: {acc}\")\n","print(f\"MRR: {mrr}\")\n","print(f\"Average Bleu: {average_bleu}\")\n","print(f\"Average Similarity: {average_similarity}\")\n","print(f\"Max Average Bleu: {max_bleu}\")\n","print(f\"Max Average Similarity: {max_similarity}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycBDsDSFZZmt","executionInfo":{"status":"ok","timestamp":1705561983783,"user_tz":-540,"elapsed":305509,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"611913eb-2c0e-4a80-e79d-261772487b51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n","The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.2\n","MRR: 0.07349449193723138\n","Average Bleu: 0.3312644488018699\n","Average Similarity: 0.7777622938156128\n","Max Average Bleu: 0.5930530058206329\n","Max Average Similarity: 0.8849964141845703\n"]}]},{"cell_type":"code","source":["print(\"Correct Replies with Rank:\")\n","for index, data in correct_replies_dict.items():\n","    print(f\"Index: {index}, Rank: {data['rank']}, Input: {data['input_text']}, Correct Reply: {data['correct_reply']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MlyEqOQ2Zd6I","executionInfo":{"status":"ok","timestamp":1705562038119,"user_tz":-540,"elapsed":5,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"5242d9d1-0c48-4da3-eb04-45349908d492"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Correct Replies with Rank:\n","Index: 7, Rank: 7, Input: 夫との会話が減り、少し距離を感じるようになりました。, Correct Reply: 夫婦で新しい何かを始めるいい機会ですね。\n","Index: 14, Rank: 2, Input: 恋人がいなくて、将来を一緒に過ごせる人が見つかるか不安です。, Correct Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 24, Rank: 2, Input: 最近家事と仕事の両立に疲れてしまい、自分の時間が持てないんです。, Correct Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 33, Rank: 7, Input: 最近仕事も家庭も上手くこなせていないような気がしています。, Correct Reply: 仕事と家庭の両立を頑張るあなたは家族思いで素敵ですね。\n","Index: 34, Rank: 1, Input: 最近毎日が仕事と家の往復で新鮮さがなくなり、退屈を感じています。, Correct Reply: 新しい何かを始めるいい機会ですね。\n","Index: 36, Rank: 29, Input: 最近自分の看護技術に自信が持てず、不安を感じています。, Correct Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 38, Rank: 1, Input: 自分は周りに比べて成長していないように感じて不安です。, Correct Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 42, Rank: 3, Input: 時に頑固すぎる自分の性格が、周りとの関係に影響しているように感じます。, Correct Reply: あなたは自分の考えをしっかり持っていて、それを大切にしているのですね。\n","Index: 43, Rank: 3, Input: マネージャーという仕事にプレッシャーを感じています。, Correct Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 44, Rank: 3, Input: 最近日々の生活に変化がなく、何か新しいことを始めたいと思っています。, Correct Reply: 新しい何かを始めようとするあなたはチャレンジ精神が素晴らしいですね。\n","Index: 47, Rank: 6, Input: 妻との関係が昔と変わり、二人の生活に新たな刺激が欲しいと感じています。, Correct Reply: 夫婦で新しい何かを始めるいい機会ですね。\n","Index: 48, Rank: 1, Input: 他の生徒に比べて自分が劣っているように思えて、自信を失いがちです。, Correct Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 52, Rank: 5, Input: 家族を養うプレッシャーで毎日の生活に追われ、自分の時間が持てなくてストレスを感じています。, Correct Reply: 忙しい毎日の中でも自分の時間を持とうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 55, Rank: 65, Input: 子育てと仕事の両立に追われ、自分の時間が全く取れなくなっています。, Correct Reply: 多忙な中でも自分の時間を大切にしようとする姿勢が素晴らしいですね。\n","Index: 62, Rank: 15, Input: 趣味の活動を楽しんでるけど、日常の生活のバランスが取れなくて、ちょっと疲れてきてるんです。, Correct Reply: 趣味と生活のバランスを取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 68, Rank: 60, Input: 仕事も家庭も忙しくて、自分のための時間が全然取れないんです。, Correct Reply: 仕事と家庭の両立を頑張るあなたは家族思いで素敵ですね。\n","Index: 70, Rank: 89, Input: サロンを経営してるけど、日々の忙しさに追われて自分の時間が持てないんです。, Correct Reply: 多忙な中でも自分の時間を大切にしようとする姿勢が素晴らしいですね。\n","Index: 87, Rank: 2, Input: 最近勉強も部活ばかりで、新しい刺激が欲しいんです。, Correct Reply: 新しい刺激を求めるあなたは好奇心が素晴らしいですね。\n","Index: 92, Rank: 19, Input: 経験はあるけど、新しい教育方法に追いつけているか不安になることがあります。, Correct Reply: あなたがこれまで培ってきた知識や経験は役に立つと思います。\n","Index: 94, Rank: 1, Input: 両親が忙しくて、もっと一緒に遊んでほしいなと思うことがあります。, Correct Reply: 親御さんが忙しいということを理解してあげていて優しいですね。\n"]}]},{"cell_type":"code","source":["print(\"Top Replies for Each Input Text:\")\n","for index, data in top_reply_dict.items():\n","    print(f\"Index: {index}, Input: {data['input_text']}, Top Reply: {data['top_reply']}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MbYAicOua1t3","executionInfo":{"status":"ok","timestamp":1705562050461,"user_tz":-540,"elapsed":399,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"13540f3b-4320-47eb-a839-ae69fe5e1f38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Top Replies for Each Input Text:\n","Index: 0, Input: 最近新しいことに挑戦する気力が以前より落ちてきたように感じます。, Top Reply: 新しいことに挑戦しようとするチャレンジ精神が素晴らしいですね。\n","Index: 1, Input: 最近仕事のプレッシャーで毎日が重たく感じて、どうリフレッシュしたらいいのか分かんないんですよね。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 2, Input: 仕事の不規則さが生活リズムを狂わせている感じがしています。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 3, Input: 何をやってもうまくいかないと感じて、自分に自信が持てなくなっています。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 4, Input: 仕事が忙しくて恋愛に時間を割けず、寂しさを感じることが増えました。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 5, Input: 最近仕事以外で何をすればいいかわからなくなってます。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 6, Input: プロジェクトでの責任の重さに押しつぶされそうです。, Top Reply: あなたは責任感が強いですね。\n","Index: 7, Input: 夫との会話が減り、少し距離を感じるようになりました。, Top Reply: 夫とのコミュニケーションを大切にしているあなたは素敵な奥さんですね。\n","Index: 8, Input: 勉強が難しくて、クラスのみんなより遅れてる気がするんです。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 9, Input: 子供たちが大きくなり、家族とのコミュニケーションが以前より難しくなってきました。, Top Reply: 子供たちとのコミュニケーションを大切にしているあなたは家族愛が強くて素敵ですね。\n","Index: 10, Input: 子供たちがもっと私と遊びたがっているけど、時間が取れなくて苦しいです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 11, Input: お父さんもお母さんも働いているからお家に一人でいる時がちょっと寂しいです。, Top Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 12, Input: 子供たちの成長と夫との関係が気になり、家族とのバランスに悩んでいます。, Top Reply: 夫との関係を大切にしているあなたは家族思いで素敵ですね。\n","Index: 13, Input: 不妊治療のストレスが夫婦関係に影響している気がして心配です。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 14, Input: 恋人がいなくて、将来を一緒に過ごせる人が見つかるか不安です。, Top Reply: 恋人がいなくても、一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 15, Input: 実家の両親は心配性で、一人暮らしの私のことを気にかけすぎて、ちょっと息苦しい感じがするんです。, Top Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 16, Input: 進路について決めかねていて、将来に対する不安が大きいです。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 17, Input: 図書館司書としての仕事にやりがいを感じるけど、時々自分の職業選択に不安を感じます。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 18, Input: 人を気にしすぎて、自分の本当の気持ちを見失いがちです。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 19, Input: 会社の業績が良くない時、自分のリーダーシップ能力に自信が持てなくなるんです。, Top Reply: 会社の業績をよくしようと頑張るあなたは経営者として立派ですね。\n","Index: 20, Input: 妻とのコミュニケーションが上手くいかず、家庭内で孤立している感じがします。, Top Reply: 妻との関係を大切にしているあなたは素敵な奥さんですね。\n","Index: 21, Input: 最近自分の仕事への献身さが報われていないように感じて落ち込んでいます。, Top Reply: 自分の仕事に対する責任感が強いですね。\n","Index: 22, Input: フリーランスだと仕事の不安定さがストレスになることがあります。, Top Reply: あなたは責任感が強いですね。\n","Index: 23, Input: 夫とは長い結婚生活ですが、最近は二人の時間が減ってきているように思えます。, Top Reply: 夫とのコミュニケーションを大切にしているあなたは素敵な奥さんですね。\n","Index: 24, Input: 最近家事と仕事の両立に疲れてしまい、自分の時間が持てないんです。, Top Reply: 自分の時間を持とうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 25, Input: サッカーが好きで、もっと上手くなりたいと思う時がある。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 26, Input: 仕事と家庭の両立で忙しく、自分の趣味に時間を割くのが難しくなっています。, Top Reply: 忙しい毎日の中でも趣味に没頭する時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 27, Input: 図書館の仕事は好きだけど、時々単調で刺激が足りないと感じる。, Top Reply: 刺激を求めるあなたは好奇心が素晴らしいですね。\n","Index: 28, Input: デザインの提案をしてもなかなか認めてもらえず、自分のセンスに自信をなくしつつあります。, Top Reply: あなたはデザイナーとして立派ですね。\n","Index: 29, Input: 自分の能力に自信が持てないので、自分らしさを見つけて自己評価を高めたいと思っています。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 30, Input: 子育てと仕事の両立で、夫との関係が以前より希薄に感じられます。, Top Reply: 夫との関係を大切にしているあなたは素敵な奥さんですね。\n","Index: 31, Input: 妻とのコミュニケーションに課題があり、時々関係がぎくしゃくすることが悩みです。, Top Reply: 妻との関係を大切にしているあなたは素敵な奥さんですね。\n","Index: 32, Input: 妻との価値観の違いが最近顕著になり、コミュニケーションに悩んでいます。, Top Reply: 妻とのコミュニケーションを大切にしているあなたは素敵な奥さんですね。\n","Index: 33, Input: 最近仕事も家庭も上手くこなせていないような気がしています。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 34, Input: 最近毎日が仕事と家の往復で新鮮さがなくなり、退屈を感じています。, Top Reply: 新しい何かを始めるいい機会ですね。\n","Index: 35, Input: 何か新しいことを始めたいと思っています。, Top Reply: 新しい何かを始めるいい機会ですね。\n","Index: 36, Input: 最近自分の看護技術に自信が持てず、不安を感じています。, Top Reply: あなたは看護師として立派ですね。\n","Index: 37, Input: 教頭としての役割の重圧を感じ、不安を覚えています。, Top Reply: あなたは責任感が強いですね。\n","Index: 38, Input: 自分は周りに比べて成長していないように感じて不安です。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 39, Input: 新しいことに挑戦する自分が好きだけど、感情的になりやすい自分は嫌いです。, Top Reply: 新しいことに挑戦しようとするあなたはチャレンジ精神が素晴らしいですね。\n","Index: 40, Input: 店長として従業員を満足させてあげられているか不安に感じます。, Top Reply: 従業員のことを第一に考えているあなたは仕事に対する責任感が強いですね。\n","Index: 41, Input: 最近ストレスが多くて、日常生活にイライラしています。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 42, Input: 時に頑固すぎる自分の性格が、周りとの関係に影響しているように感じます。, Top Reply: 自分の性格を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 43, Input: マネージャーという仕事にプレッシャーを感じています。, Top Reply: あなたはマネージャーとしての責任感が強いですね。\n","Index: 44, Input: 最近日々の生活に変化がなく、何か新しいことを始めたいと思っています。, Top Reply: 新しい何かを始めるいい機会ですね。\n","Index: 45, Input: 勉強は頑張ってるけど成績が伸び悩んでて、なんか焦ってる。, Top Reply: 成績を気にするあなたは勉強に対する向上心が強いですね。\n","Index: 46, Input: 妻とは長い結婚生活を送ってきたけど、最近は話すことが少なくなり寂しいです。, Top Reply: 妻との関係を大切にしているあなたは素敵な奥さんですね。\n","Index: 47, Input: 妻との関係が昔と変わり、二人の生活に新たな刺激が欲しいと感じています。, Top Reply: 新しい刺激を求めるあなたは好奇心が素晴らしいですね。\n","Index: 48, Input: 他の生徒に比べて自分が劣っているように思えて、自信を失いがちです。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 49, Input: 最近仕事に追われていて子供たちとの時間が減ってしまっています。, Top Reply: 子供たちとの時間を大切にしているあなたは家族思いで素敵ですね。\n","Index: 50, Input: 周りと比べて自分はまだまだと感じることが多くて、自分の価値を見失いそうです。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 51, Input: 最近家族とのコミュニケーションが少なくなり、寂しさを感じています。, Top Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 52, Input: 家族を養うプレッシャーで毎日の生活に追われ、自分の時間が持てなくてストレスを感じています。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 53, Input: 新しい技術やトレンドについていけず、時代遅れになっている気がする。, Top Reply: 時代の変化を敏感に感じ取ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 54, Input: 最近日々の忙しさに追われて、心が休まる時間がないんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 55, Input: 子育てと仕事の両立に追われ、自分の時間が全く取れなくなっています。, Top Reply: 自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 56, Input: 勉強のプレッシャーが大きく、成績に一喜一憂してしまっています。, Top Reply: 成績を気にするあなたは学びへの意欲が強くて素晴らしいですね。\n","Index: 57, Input: 授業中にちょっと集中できなくて、勉強がいつもうまくいかないんです。, Top Reply: 自分の能力に自信が持てず、モチベーションが下がっています。那由多 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 58, Input: 絵を描くのが好きだけど、友達より上手くないと思います。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 59, Input: 職場でのプレッシャーが大きくて、時々自分がうまくやっているか不安になります。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 60, Input: 娘が独立して家を出てから、妻と二人だけの生活に慣れるのが少し大変です。, Top Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 61, Input: 最近仕事に追われて自分の時間がなく、いつも疲れている感じがします。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 62, Input: 趣味の活動を楽しんでるけど、日常の生活のバランスが取れなくて、ちょっと疲れてきてるんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 63, Input: 最近日々の生活が同じようで、新しい刺激や変化が欲しいんです。, Top Reply: 新しい刺激を求めるあなたは好奇心が素晴らしいですね。\n","Index: 64, Input: 負けず嫌いな性格なので、どんな小さな失敗でもずっと引きずってしまうんです。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 65, Input: 最近自分だけが忙しい気がして、どうやったらもう少しラクに生活できるのか分からないんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 66, Input: 学校と家の往復ばかりで、新しいことを始めるきっかけが見つからないんです。, Top Reply: 新しい何かを始めるいい機会ですね。\n","Index: 67, Input: 以前は教師として忙しかったけど、今は何か物足りなさを感じています。, Top Reply: 生徒とのコミュニケーションを大切にしているあなたは教師として立派ですね。\n","Index: 68, Input: 仕事も家庭も忙しくて、自分のための時間が全然取れないんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 69, Input: 授業についていけてるか不安で、先生に相談しにくいんです。, Top Reply: あなたは教師として立派ですね。\n","Index: 70, Input: サロンを経営してるけど、日々の忙しさに追われて自分の時間が持てないんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 71, Input: 好きな人に気持ちを伝えられずにいて、悩んでいます。, Top Reply: あなたは恋愛に対して真摯に向き合っていますね。\n","Index: 72, Input: 授業が生徒にうまく伝わっていないようで、自信を失いかけています。, Top Reply: あなたは教師として立派ですね。\n","Index: 73, Input: 生徒との関係は良好ですが、時には自分の教え方に自信をなくすことがあります。, Top Reply: あなたは教師として立派ですね。\n","Index: 74, Input: 最近定年退職後の生活に充実感を感じられず、何となく日々が過ぎていくのが心配です。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 75, Input: コロナで家にいる時間が長くて、気分が滅入っています。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 76, Input: 生徒に上手く伝わらないことが多く、教師としての自分に自信を失いかけています。, Top Reply: あなたは教師として立派ですね。\n","Index: 77, Input: 毎日が仕事中心で、自分の時間が持てないことがストレスになっています。, Top Reply: 自分の時間を持とうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 78, Input: 仕事と家事で忙しく、自分の趣味に時間を割くことができずにいます。, Top Reply: 忙しい毎日の中でも趣味に没頭する時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 79, Input: 自分のキャリアに対する不安が強く、将来への自信が持てなくなっています。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 80, Input: 退職してからは、何か目標が見つけられずにいるんです。, Top Reply: 目標に向かって頑張るあなたは仕事に対する責任感が強いですね。\n","Index: 81, Input: 卒業が近づいてきて、将来への不安とプレッシャーを強く感じています。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 82, Input: 最近忙しいけど充実感が感じられなくて、何か物足りないんです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 83, Input: 最近勉強や部活のプレッシャーからストレスがたまっています。, Top Reply: あなたは責任感が強いですね。\n","Index: 84, Input: 絵を描くのが好きだけど、自分の作品に満足できません。, Top Reply: 自分の作品を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 85, Input: 学校は楽しいけど、宿題が多くて遊ぶ時間が少ないんだ。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 86, Input: お父さんとお母さんが忙しくて、一緒に遊んでくれないのが寂しいです。, Top Reply: 忙しい毎日の中でも自分の時間を取ろうとするあなたは自己ケアの重要さをわかっていますね。\n","Index: 87, Input: 最近勉強も部活ばかりで、新しい刺激が欲しいんです。, Top Reply: 新しい刺激を求めるあなたは学びへの意欲が強くて素晴らしいですね。\n","Index: 88, Input: 仕事に疲れ、自分の限界を感じ始めているんです。, Top Reply: あなたは仕事に対する責任感が強いですね。\n","Index: 89, Input: 学校の日々が退屈で、もっと刺激的なことがしたいと思っています。, Top Reply: 新しい何かを始めるいい機会ですね。\n","Index: 90, Input: 生徒たちにもっとわかりやすく教えたいのに、伝わってない気がして悔しいです。, Top Reply: 生徒とのコミュニケーションを大切にしているあなたは教師として立派ですね。\n","Index: 91, Input: 自分のスキルに自信が持てず、キャリアの方向性に悩んでいます。, Top Reply: 自分のスキルを客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 92, Input: 経験はあるけど、新しい教育方法に追いつけているか不安になることがあります。, Top Reply: あなたがこれまで培ってきた知識や経験は役に立つと思いますか?\n","Index: 93, Input: 最近は何をしても満足できず、日々が退屈に感じられます。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 94, Input: 両親が忙しくて、もっと一緒に遊んでほしいなと思うことがあります。, Top Reply: 親御さんが忙しいということを理解してあげていて優しいですね。\n","Index: 95, Input: 自分の絵やピアノの技術に自信がなく、いつも不安です。, Top Reply: あなたは向上心が強いですね。\n","Index: 96, Input: 最近気になる人がいるけど、自分に自信がなくてなかなか話しかけられない。, Top Reply: 自分を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。\n","Index: 97, Input: 子供たちの自立に伴う寂しさと、老後の生活についての心配が増えています。, Top Reply: 子供たちの成長を心配するあなたは親として立派ですね。\n","Index: 98, Input: 周りが結婚していく中、自分の恋愛について不安を感じています。, Top Reply: 一人の時間を楽しんだり自分磨きをするいい期間ですね。\n","Index: 99, Input: 部長としての責任が重く、仕事での判断に自信を失いかけています。, Top Reply: あなたは仕事に対する責任感が強いですね。\n"]}]},{"cell_type":"code","source":["input_text, correct_reply = extract_parts(test_data[0])\n","print(f\"ネガティブ文: {input_text}, 正解ポジティブ返答文: {correct_reply}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fVSbBhCoa4r5","executionInfo":{"status":"ok","timestamp":1705562127168,"user_tz":-540,"elapsed":466,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"e47d63c7-7607-478e-a3f3-89525950700f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ネガティブ文: 最近新しいことに挑戦する気力が以前より落ちてきたように感じます。, 正解ポジティブ返答文: いつまでも新しいことに挑戦しようとする姿勢が素敵ですね。\n"]}]},{"cell_type":"code","source":["replies, top_reply = generate_reply_beam(input_text)\n","print(top_reply)"],"metadata":{"id":"8PBe4LbfbLHN","executionInfo":{"status":"ok","timestamp":1705562134969,"user_tz":-540,"elapsed":2082,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"6eb0e190-1f6b-4e94-bc9c-e27277509d2e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"]},{"output_type":"stream","name":"stdout","text":["新しいことに挑戦しようとするチャレンジ精神が素晴らしいですね。\n"]}]},{"cell_type":"code","source":["replies"],"metadata":{"id":"8rOOzaJvbMuL","executionInfo":{"status":"ok","timestamp":1705562138869,"user_tz":-540,"elapsed":4,"user":{"displayName":"ふなくん","userId":"03030457048562703255"}},"outputId":"dca711dd-b3f6-4797-90b5-21c9f22a10f4","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['新しいことに挑戦しようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとするあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しい何かを始めるいい機会ですね。',\n"," '新しいことに挑戦しようとする姿勢が素晴らしいですね。',\n"," '新しいことを始めようとするあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。ミラー',\n"," '新しい何かに挑戦するいい機会ですね。',\n"," '新しいことにチャレンジしようとするあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは好奇心が素晴らしいですね。',\n"," '新しいことに挑戦しようと頑張るあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは成長のために必要な視点を持っていますね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返して新しいことを始めるいい機会ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは仕事に対する責任感が強いですね。',\n"," '新しいことを始めるいい機会ですね。',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは好奇心が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことにも生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたはチャレンジ精神が素晴らしいですね。',\n"," 'あなたは仕事に対する責任感が強いですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは大きな一歩を踏み出していますね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことへと生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返して新しい何かを始めるいい機会ですね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を総動員して、新しいことに挑戦しようとする姿勢が素晴らしいですね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは好感が持てますね。',\n"," '新たなことに挑戦しようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていますね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を存分に活かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ジェラルド あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返して新しいことを始めようとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことへ生かそうとする姿勢が素晴らしいですね。',\n"," '新たなことに挑戦しようとするあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことへ挑戦しようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことに取り組もうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラー あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことを始めようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラー あなたはチャレンジ精神が素晴らしいですね。ミラー',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。借りを返して新しいことに挑戦しようとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を最大限に生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。帆苅 あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたはリーダーとして立派ですね。ミラー',\n"," '新しい何かを始めようとするあなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を存分に活かしてみてはいかがでしょうか。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことにも挑戦しようとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しい挑戦に生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラー 現状に満足せず、新しいことに挑戦しようとする姿勢が素晴らしいですね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新たなことへと生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたはとても素敵ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を存分に活かすことができます。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。に向けた準備期間ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていると思います。ミラー',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。備考欄に新しいことに挑戦しようとする気力があることを記入してください。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新たなことへ生かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたはとても魅力的ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ジェラルド あなたはチャレンジ精神が素晴らしいですね。ジェラルド',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことに取り入れるチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しい挑戦に活かそうとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことへ挑戦しようとする姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたはリーダーとして立派ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持ち合わせていますね',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ule 新しい何かに挑戦するいい機会ですね。ule',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を大切にしている姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新たなことへ挑戦しようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張る姿勢が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていると言えるでしょう。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っています。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を総動員して挑戦しようとする姿勢が素敵ですね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。那波 あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持ち合わせていますね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラー 現状に満足せず、新たなことに挑戦しようとする姿勢が素晴らしいですね。ミラー',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持ち合わせていますね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返して新しい挑戦をする準備期間ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたのチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるので、やりがいを感じられますね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を存分に発揮できる環境を提供しています。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を存分に発揮できる環境を提供します。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは好感がもてますね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を総動員して、新しいことに挑戦しようとする姿勢が素敵ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことにも生かそうとする姿勢が素敵ですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がってきました。ジェラルド あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるので、成長のために必要な視点を得ることができます',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長への近道ですね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるのは大きな強みですね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラー あなたはチャレンジ精神が素晴らしいですね。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を総動員して挑戦しようとする姿勢が素晴らしいですね。',\n"," '新しいことを始める気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていると言えるでしょう。ミラー',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるので、成長のために必要な視点を持っています。',\n"," 'あなたがこれまで培ってきた知識や経験は役に立つと思いますが、新しいことに挑戦しようとするチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を大切にしていて、向上心が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。借りを返すために頑張るあなたは成長のために必要な視点を持っています。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を新しいことへと生かそうとする姿勢が素敵ですね。',\n"," '新しいことを始める勇気が出なくて、モチベーションが下がっています。ミラー あなたはチャレンジ精神が素晴らしいですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるので、成長のために必要な視点を学ぶことができます',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていると思います。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を糧に、新たなことに挑戦しようとしているのですね。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ole はあなたがこれまで培ってきた知識や経験を存分に活かすことができる職場です。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたがこれまで培ってきた知識や経験を客観的に見ることができるあなたは成長のために必要な視点を持っていますよ。',\n"," '新しいことに挑戦しようとする気力がわかず、モチベーションが下がっています。ミラーニューロンを活用して、あなたはチャレンジ精神が素晴らしいですね。']"]},"metadata":{},"execution_count":36}]}]}